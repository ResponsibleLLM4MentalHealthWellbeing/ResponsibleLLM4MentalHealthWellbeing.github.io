# Responsible LLM for Mental Health and Wellbeing

Welcome to the 1st CHI workshop on Responsible LLM for Mental Health and Wellbeing.

Primary Contact: Ryan Louie (rylouie@cs.stanford.edu)

**Call for Participation**: High costs, shortages of qualified providers, and other barriers have driven many people to use large language models (LLMs) for therapy. Yet, the startling number of reported harms and the rapid regulations banning LLM therapy chatbots demands the research community create an agenda for responsible LLM uses for mental health and well-being. In this workshop, we seek to bring together AI experts, policy makers, HCI experts, and impacted community members to share knowledge in this rapidly evolving research area, and solidify a research agenda to quickly provide policymakers, AI deployers, and the public with effective tools and recommendations to mitigate harms. The schedule spans two 90-minutes slots and will involve two invited talks, a panel discussion, poster presentations that extend into the coffee break, and sequential breakout group discussions on two key topics. Relevant areas may include (1) analyzing mechanisms of harm, such addiction, sycophancy, delusions, (2) evaluating safety using static probes or agentic simulations grounded in clinical psychology; (3) designing interventions at the interface, policy, model training or system deployment levels; (4) investigating how identity and culture impacts access and harms; and (5) designing AI applications for non-therapeutic uses (e.g., assistive workflows, LLM skill training) that address resource-constraints in mental health care systems. Join some of the organizers and an expected 25 - 50 participants in-person! We invite 2-4 page position papers (excluding references) submitted via our [website's submission page](https://responsiblellm4mentalhealthwellbeing.github.io/submit). Accepted papers will be published together according to ArXiV report numbers.
